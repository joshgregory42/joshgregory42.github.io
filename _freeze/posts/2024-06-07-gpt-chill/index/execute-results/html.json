{
  "hash": "72f8ec3051a68d6576842d41b01cc29c",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"GPT and Chill Notes\"\ndescription: \"Notes from the GPT and Chill [playlist](https://www.gptandchill.ai/codingproblems)\"\nauthor:\n  - name: Josh Gregory\n    url: https://joshgregory.github.io/\n    orcid: 0000-0002-4368-1171\n    affiliation: College of Engineering & Applied Science, University of Colorado Boulder\n    affiliation-url: https://www.colorado.edu/mechanical/ \ndate: 06-07-2024\nlast-modified: today\ncategories: [Notes, Deep Learning, Machine Learning, Artificial Intelligence] # self-defined categories\ncitation: \n  url: https://joshgregory42.github.io/posts/2024-06-07-gpt-chill/ \ndraft: false # setting this to `true` will prevent your post from appearing on your listing page until you're ready!\n---\n\n# How Neural Networks Learn (Gradient Descent)\n\n\n{{< video https://www.youtube.com/watch?v=bbYdqd6wemI >}}\n\n\n\nLet's assume that we have a model that takes two inputs: $x_1$ (your weight at age 10) and $x_2$ (your height at age 10) and outputs a prediction $y$ for your final height as an adult.\n\nGradient descent is just a way to minimize a function. That's it. So if I have a function like $y = x^2$, we can minimize this pretty easily by taking the derivative and setting it equal to zero:\n\n$$\n\\begin{align*}\ny &= x^2\\\\\ny' &= 2x\\\\\n2x &= 0\\\\\nx &= 0\n\\end{align*}\n$$\n\nwhich corresponds to the minimum of $y = x^2$. But that's only for one input and one output. We usually have multiple inputs (like here it's height and weight). So how can we handle that? What if we can't even take the derivative?\n\nLet's back up and ask a more important question first. Why do we even **need** to minimize a function to train a model?\n\nThe function we're minimizing is the **error function**. Aka the **loss** or the **cost function**, it is the error between the model's prediction and the **label** (the actual value). In our example here, the error would be the difference between what the model *thinks* the final height should be given a 10 year-old's weight ($x_1$) and height ($x_2$), and what the height *actually* is (the label). There are different ways we can calculate the error, but here we could do something simple like the absolute difference:\n\n$$\n\\begin{equation*}\n\\text{Error} \\approx \\left| \\text{Prediction} - \\text{label} \\right|\n\\end{equation*}\n$$\nLet's build some intuition. Let's return to $y = x^2$. Gradient descent is typically called \"stochastic gradient descent\" (SGD), with \"stochastic\" referring to a random guess for the minimum. Let's apply that here to $y = x^2$. Let's have an initial guess of $x=3$ (remember that we know the actual minimum is $x = 0$). Let's look at the slope of the tangent line at $x = 3$, which is the same thing as the *derivative* or the *gradient*. Here it is positive:\n\n$$\n\\begin{align*}\nf' &= 2 x\\\\\nf' (x = 3) &= (2)(3) = 6\n\\end{align*}\n$$\n\nwhich means that the function is **increasing**. If we want to minimize a function, we want to go in the opposite direction. We want to find where there is no change ($f'=0$), assuming the boundaries of the function do not contain the minima (that's an easy check though). So our new guess:\n\n$$\n\\text{New guess} = \\text{old guess} - \\left( \\text{slope} \\right) \\left( \\text{step size} \\right)\n$$\nLet's call the step size $\\alpha$. So more succinctly:\n\n$$\n\\text{Guess} -= \\text{slope} \\cdot \\alpha\n$$\nIn Python, we could write a class that implements this:\n\n```python\nclass GradDescent:\n    def get_minimizer(self, iterations: int, learning_rate: float, guess: int) -> float:\n        for i in range(0, iterations):\n            guess -= (2*guess)*learning_rate\n\n        x = round(guess, 5)\n        \n        return x\n\nsol = GradDescent()\n\nx = sol.get_minimizer(iterations=10, learning_rate=0.01, guess=5)\n\nprint(x)\n```\n## Multivariate Gradient Descent\n\nLet's say that we have a new function related with two variables:\n\n$$\nf(x,y) = x^2 + y^2\n$$\nNow we have an actual gradient, that is\n\n$$\n\\begin{align*}\n\\nabla f(x,y) &= \\left \\langle \\frac{\\partial f}{ \\partial x }, \\frac{\\partial f}{ \\partial y } \\right \\rangle\\\\\n&= \\left \\langle 2x, 2y \\right \\rangle\n\\end{align*}\n$$\nSo now we have two values to update (one for each component, $x$ and $y$), which means that we also need two initial guesses for $x$ and $y$. So our updating algorithm now looks like this for $x$:\n\n$$\n\\begin{align*}\n\\text{guess} &-= \\frac{\\partial f}{ \\partial x } \\bigg|_{x=x_{\\text{guess}}} \\cdot \\alpha\\\\\n&-= 2 x \\bigg|_{x=x_{\\text{guess}}} \\alpha \n\\end{align*}\n$$\nand for $y$:\n$$\n\\begin{align*}\n\\text{guess} &-= \\frac{\\partial f}{ \\partial y } \\bigg|_{y=y_{\\text{guess}}} \\cdot \\alpha\\\\\n&-= 2 y \\bigg|_{y=y_{\\text{guess}}} \\alpha \n\\end{align*}\n$$\nNote that the partial derivatives being the same here is purely a coincidence and is only because $f(x,y)$ is defined as $f(x, y)=x^2 + y^2$. If we had changed it to something like $f(x, y) = x^3 - y^{1/2}$ or something like that, then the partial derivatives would obviously not be equal.\n\nIf you do the calculus, you find that the minimum of $f(x,y)$ is at (0, 0). Here's the code verifying that:\n\n```python\nclass GradDescentMulti:\n    def get_min(self, iterations: int, learning_rate: float, guess_x: int, guess_y: int) -> float:\n        for _ in range(0, iterations):\n            guess_x -= 2*guess_x * learning_rate\n            guess_y -= 2*guess_y * learning_rate\n\n            guess_x = round(guess_x, 5)\n            guess_y = round(guess_y, 5)\n        return guess_x, guess_y\n\ngd = GradDescentMulti()\n\nx_min, y_min = gd.get_min(iterations=1000, learning_rate=0.1, guess_x = 2, guess_y = 5)\n\nprint(f'x_min: {x_min}, y_min: {y_min}')\n```\n\n```bash\nx_min: 2e-05, y_min: 2e-05\n```\nwhich within rounding precision is equal to zero for both $x$ and $y$.\n\n# Linear Regression: Full Explanation & Coding Problem\n\n\n{{< video https://www.youtube.com/watch?v=K9xTjTP0vVw >}}\n\n\n\nLinear regression is the foundation of neural networks and it behind many of the recent advancements in ChatGPT, self-driving, and deepfakes.\n\n## The \"Regression\" part\n\n### Classification\n\nLet's start with a more intuitive example, which is actually the opposite of regression and it's **classification**. As an example, let's say that we're building a model that detects whether someone has diabetes. There are two (simplified) outcomes here: the person has diabetes or they don't. So we're classifying our input (maybe an image) into two classification \"buckets\".\n\nA more complicated example would be an object-detection model. So you give your model an input image and it tells you whether it's a cat, a dog, an apple, or an orange. This is the same as the diabetes example, just with more classification buckets.\n\n### Regression\n\nFor regression, the output is a number that is real (between negative and positive infinity). So if you want a model that will predict someone's final height given their current height, current weight, how tall their parent's are (and possibly any other relevant features), the output exists on some scale (so a number). Unlike classification, regression returns a number (for our example, something like 70, for 70 inches in height which is 5'10\") instead of a category (like \"orange\").\n\n\n## The \"Linear\" part\n\nWhen we're building our model, we want it to make some kind of prediction given some piece of information we provide. The **linear** part here is saying that the relationship between the input to the model (like the current height, current weight, parent's height, etc.) and the output (final height) is linear, so it looks something like this:\n\n$$\nh(x, y, z) = w_1 x + w_2 y + w_3 z + b\n$$\nwhere\n\n$$\n\\begin{align*}\nh &\\text{ is the final height}\\\\\nx &\\text{ is the current weight}\\\\\ny &\\text{ is the current height}\\\\\nz &\\text{ is the parents' height}\\\\\nw_n &\\text{ is the model weight}\\\\\nb &\\text{ is the model bias}\\\\\n\\end{align*}\n$$\nThe \"linear\" part is from $h(x, y, z)$ being a linear equation. So there isn't anythng like $w_1 x^4$ or $w_2 \\cos{y}$. This means that, in short, we have a *really fancy version of* $y = mx + b$, but $m$ and $x$ can have an arbitrary number of components or inputs.\n\nThen, during training via gradient descent, the model will improve $w_1, w_2, w_3, \\ldots, w_n$ and $b$ over some fixed number of iterations until the model is a pretty good way to predict someone's final height given their current height, weight, and that of their parents.\n\nThe pseudocode for this would look something like:\n\n```python\nfor num_iterations:\n  get_model_prediction()\n  get_error() # want this to approach zero\n  get_derivatives()\n  update_weights()\n```\n\nFocusing a bit more on the `get_error()` part, there are many different ways we can determine the error in a model, but one of the most common ones is called **Mean Squared Error** (MSE):\n\n$$\n\\text{MSE} = \\sum_{i = 1}^{N} \\frac{\\left( \\text{prediction}_i - \\text{label}_i \\right)^2}{N}\n$$\nwhere $N$ is the number of training examples, and recall that the label is defined as the \"true\" answer that we're comparing our model's prediction against.\n\nA common question to ask here is why don't we use the absolute value instead of squaring to get our error? This is because the derivative won't exist somewhere. If we look at the most basic absolute value function, $y = |x|$, we get something like this:\n\n::: {#b58263bb .cell execution_count=1}\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-2-output-1.png){width=585 height=429}\n:::\n:::\n\n\nwhich has an undefined derivative at the origin (technically, this makes the absolute value function \"non-differentiable\"). In other words, for $y = |x|$, $y'$ doesn't exist at $x=0$, which would break the algorithm that we've developed so far. Squaring solves this problem and still gives us the same general idea as the absolute value, that is, tells us how good/bad the error is.\n\nImplementing this in code, we use vectors and matrices:\n\n$$\n\\begin{bmatrix}\nx & y & z\n\\end{bmatrix}\n\\begin{bmatrix}\nw_1\\\\\nw_2\\\\\nw_3\n\\end{bmatrix}\n= w_1 x + w_2 y + w_3 z = \\text{model prediction}\n$$\nBut what if we had many people? Let's look at what this would look like if we had three people:\n$$\n\\begin{bmatrix}\nx_1 & y_1 & z_1\\\\\nx_2 & y_2 & z_2\\\\\nx_3 & y_3 & z_3\n\\end{bmatrix}\n\\begin{bmatrix}\nw_1\\\\\nw_2\\\\\nw_3\n\\end{bmatrix}\n=\n\\begin{bmatrix}\nw_1 x_1 + w_2 y_1 + w_3 z_1\\\\\nw_1 x_2 + w_2 y_2 + w_3 z_2\\\\\nw_1 x_3 + w_2 y_3 + w_3 z_3\\\\\n\\end{bmatrix}\n$$\nwhere each row is the model's prediction for each person (i.e. the first row is the model's prediction for the first person, second row is the prediction for the second person, etc.). An important note here is that at this point we're just doing matrix multiplication. The main advantage of doing this in matrices vs. a loop is the following:\n\n<p style=\"text-align: center;\">**Programs can do this EXTREMELY fast**</p>\n\n## Implementation\n\n### Solution - First Problem\n\nMy solution to the first coding problem:\n\n```python\nimport numpy as np\nfrom numpy.typing import NDArray\n\n\n# Helpful functions:\n# https://numpy.org/doc/stable/reference/generated/numpy.matmul.html\n# https://numpy.org/doc/stable/reference/generated/numpy.mean.html\n# https://numpy.org/doc/stable/reference/generated/numpy.square.html\n\nclass Solution:\n    \n    def get_model_prediction(self, X: NDArray[np.float64], weights: NDArray[np.float64]) -> NDArray[np.float64]:\n        pred = np.matmul(X, weights)\n\n        return np.round(pred, 5)\n\n        # X is an Nx3 NumPy array\n        # weights is a 3x1 NumPy array\n        # HINT: np.matmul() will be useful\n        # return np.round(your_answer, 5)\n\n\n    def get_error(self, model_prediction: NDArray[np.float64], ground_truth: NDArray[np.float64]) -> float:\n\n        error = np.mean(np.square(model_prediction - ground_truth))\n\n        return round(error, 5)\n\n        # model_prediction is an Nx1 NumPy array\n        # ground_truth is an Nx1 NumPy array\n        # HINT: np.mean(), np.square() will be useful\n        # return round(your_answer, 5)\n```\n\n### Solution - Second Problem\n\n```python\nimport numpy as np\nfrom numpy.typing import NDArray\n\n\nclass Solution:\n    def get_derivative(self, model_prediction: NDArray[np.float64], ground_truth: NDArray[np.float64], N: int, X: NDArray[np.float64], desired_weight: int) -> float:\n        # note that N is just len(X)\n        return -2 * np.dot(ground_truth - model_prediction, X[:, desired_weight]) / N\n\n    def get_model_prediction(self, X: NDArray[np.float64], weights: NDArray[np.float64]) -> NDArray[np.float64]:\n        return np.squeeze(np.matmul(X, weights))\n\n    learning_rate = 0.01\n\n    def train_model(\n        self, \n        X: NDArray[np.float64], \n        Y: NDArray[np.float64], \n        num_iterations: int, \n        initial_weights: NDArray[np.float64]\n    ) -> NDArray[np.float64]:\n\n        for _ in range(num_iterations):\n            model_pred = self.get_model_prediction(X, initial_weights)\n\n            d1 = self.get_derivative(model_pred, Y, len(X), X, 0)\n            d2 = self.get_derivative(model_pred, Y, len(X), X, 1)\n            d3 = self.get_derivative(model_pred, Y, len(X), X, 2)\n\n            initial_weights[0] = initial_weights[0] - d1 * self.learning_rate\n            initial_weights[1] = initial_weights[1] - d2 * self.learning_rate\n            initial_weights[2] = initial_weights[2] - d3 * self.learning_rate\n\n        return np.round(initial_weights, 5)\n```\nI initially struggled with this problem due to some of the syntax and eventually had to look at the solution because I was so stuck. I was quite close in my solution (basing the derivative section off of what I did for multivariate gradient descent), however I originally thought that `desired_weight` was what we wanted the weights to be at the end of training, which was confusing. It's really just pointing to which weight we want to update (so for $w_1$, `desired_weight=0`. for $w_2$, `desired_weight=1`, etc.).\n\n# Neural Networks in 10 Minutes - End to End Explanation\n\n\n{{< video https://www.youtube.com/watch?v=KL2EaTs8r8I >}}\n\n\n\n\n![Neural network architecture](images/network.svg){width=60%}\n\n\nInput attributes:\n\n$$\n\\begin{align*}\nx_1 &\\colon \\text{parents' heights}\\\\\nx_2 &\\colon \\text{current height}\\\\\nx_3 &\\colon \\text{current weight}\\\\\n\\end{align*}\n$$\n\n## Linear Regression\n\nNeed linear regression to explain the connections and the hidden layer. Here's the formula again:\n\n$$\ny = w_1 x_1 + w_2 x_2 + w_3 x_3 + b\n$$\nRemember that $x_n$ are the input attributes and $y$ is the model's output/prediction. The weights $w_n$ then determine the relative importance of each input parameter they are associated with. For example, $w_1$ determines how important $x_1$ (in this case the average parents' height) is on someone's final height ($y$).\n\nWhat about the bias?\n\nIn this context, it would probably be some base height, since a final height of zero doesn't make much sense.\n\n## Hidden Layer\n\nEach of the hidden nodes is doing linear regression. Each node is calculating some $y$ ($y_1$, $y_2$, $y_3$, ...) based on $x_1$, $x_2$, and $x_3$ from the previous layer. This means that each node in the hidden layer (since it is calculating a $y$) is learning a $w_1$, $w_2$, and $w_3$ independently of the other nodes in that same layer (i.e. $y_1 \\neq y_2$).\n\n## Output Layer\n\nWe can think of the two outputs as $O_1$ and $O_2$. Just as in the previous layer, $O_1$ and $O_2$ are also calculated using a linear regression formula:\n\n$$\n\\begin{align*}\nO_1 &= w_1 y_1 + w_2 y_2 + w_3 y_3 + w_4 y_4 + b\\\\\nO_2 &= w_1 y_1 + w_2 y_2 + w_3 y_3 + w_4 y_4 + b\\\\\n\\end{align*}\n$$\n\nBUT the difference here is that the $w$'s and the $b$ for $O_1$ are learned independently from $O_2$ and are going to be different. \n\nIf the point of the model is to predict someone's final height, that final prediction may be from averaging $O_1$ and $O_2$. Training then is figuring out what $w_1$, $w_2$, $w_3$, $w_4$, and $b$ should be for $y_1$ - $y_4$ such that the error is minimized. The same thing is done for $O_1$ and $O_2$.\n\n# Intro to PyTorch. Forget TensorFlow\n\n\n{{< video https://www.youtube.com/watch?v=SxwtCEDHXe8&list=PLf2BgkdQjMYsyPx7HPO4M6aqTfPl2iEPx&index=8 >}}\n\n\n\nPyTorch might be the only library that is needed. Might need some other libraries like NumPy or Pandas, but can usually get away with only using PyTorch. Fundamental data type here is the **Tensor**. PyTorch (and the Tensor data type more specifically) will also take care of all the ugly math, like nasty derivatives and huge matrix multiplications.\n\n\n```python\n>>> a = torch.ones(5, 5)\n>>> print(a)\n\ntensor([[1., 1., 1., 1., 1.],\n        [1., 1., 1., 1., 1.],\n        [1., 1., 1., 1., 1.],\n        [1., 1., 1., 1., 1.],\n        [1., 1., 1., 1., 1.]])\n```\n\nFirst two important functions in PyTorch is `sum()` and `mean()`:\n\n```python\n>>> sum = torch.sum(a, axis=1) # Note that axis=1 corresponds to the rows, NOT the columns\n>>> print(sum) # Print the sum of each column\n\ntensor([5., 5., 5., 5., 5.])\n```\nAlso have `squeeze()` and `unsqueeze()`, which is used when we have unnecessary dimensions\n\n```python\n>>> a = torch.ones(5, 1)\n>>> print(a.shape)\n\ntorch.Size([5, 1])\n```\nBut the 1 is kind of unnecessary. Saying 5 x 1 is kind of unnecessary. So if we want to get rid of the 1 we can use the `squeeze()` method:\n\n```python\n>>> print(a.shape)\n>>> squeezed = torch.squeeze(a)\n>>> print(squeezed.shape)\n\ntorch.Size([5, 1])\ntorch.Size([5])\n```\n\nWhile this may seem like a small difference, it will have an impact on functions later on. Here's the difference in a more visual way:\n\n```python\n>>> print(a)\n>>> print(squeezed)\n\ntensor([[1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.]])\ntensor([1., 1., 1., 1., 1.])\n```\nIf we can squeeze something, we should also have some way to unsqueeze as well. If we're passing in two tensors, like one for training and one for validation, they both need to be the same size. We can't have one look like `a` and one look like `squeezed`.\n\nHere, the argument `dim` is where we want to insert that extra dimension. So to make our tensor `unsqueezed` 5x1 instead of just 5, we pass `dim=1`:\n\n```python\n>>> unsqueezed = torch.unsqueeze(squeezed, dim=1)\n>>> print(unsqueezed.shape)\n>>> print(unsqueezed)\n\ntorch.Size([5, 1])\ntensor([[1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.]])\n```\nIf instead we pass `dim=0`, we get the opposite:\n\n```python\n>>> unsqueezed = torch.unsqueeze(squeezed, dim=0)\n>>> print(unsqueezed.shape)\n>>> print(unsqueezed)\n\ntorch.Size([1, 5])\ntensor([[1., 1., 1., 1., 1.]])\n```\n\n## Defining Neural Network Models in PyTorch\n\nWe want something that looks like this:\n\n```python\nclass MyModel:\n    # Constructor - layers\n\n    # Forward pass - get_model_prediction(example_datapoint)\n\n```\n\n### `Module` Class\n\nPyTorch has something like this, it's called the [`Module`](https://pytorch.org/docs/stable/generated/torch.nn.Module.html) class. A `Module` is basically the same thing as a model. **Every model we create in PyTorch is going to inherit or subclass `torch.nn.Module`**.\n\n### `Linear` Class\n\nRemember that each layer in a neural network contains a bunch of nodes that are just doing linear regression based on the previous layer's input attributes, so we need some class that can take in the previous layer's input attributes, do linear regression, and then output them. That is what the [`Linear` ](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html) class does. \n\n\n### Example\n\nIf you just Google \"Neural network\", you might find something like this:\n\n![Neural network architecture. [Source](https://victorzhou.com/series/neural-networks-from-scratch/)](images/neural_network.svg){width=60%}\n\nLet's build it!\n\nLooks like our input layer has four nodes, and we have two hidden layers and one output layer. So we're going to have three instances of `nn.Linear`.\n\n```python\nclass MyModel(nn.Module):\n    # Create constructor\n    def __init__(self):\n        super().__init__()\n        self.first_layer = nn.Linear(in_features=4, out_features=6)\n        self.second_layer = nn.Linear(in_features=6, out_features=6)\n        self.final_layer = nn.Linear(in_features=6, out_features=2)\n\n    # Create forward pass\n    def forward(self, x):\n        # Calling the forward method from the nn.Module class\n    #  first_layer_output = self.first_layer.forward(x)\n       # Can also do the following:\n       #  first_layer_output = self.first_layer(x)\n\n        return self.final_layer(self.second_layer(self.first_layer.forward(x)))\n```\n\n```python\n>>> model = MyModel()\n>>> example_datapoint = torch.randn(1, 4)\n>>> model.forward(x=example_datapoint) # Can also write model(x=example_datapoint)\n\ntensor([[-0.4633, -0.0682]], grad_fn=<AddmmBackward0>)\n```\nThen we need to train the model for some number of iterations. We can then actually use the model to get predictions.\n\n\n## Coding Problem Solution\n\n```python\nimport torch\nimport torch.nn\nfrom torchtyping import TensorType\n\n# Helpful functions:\n# https://pytorch.org/docs/stable/generated/torch.reshape.html\n# https://pytorch.org/docs/stable/generated/torch.mean.html\n# https://pytorch.org/docs/stable/generated/torch.cat.html\n# https://pytorch.org/docs/stable/generated/torch.nn.functional.mse_loss.html\n\n# Round your answers to 4 decimal places using torch.round(input_tensor, decimals = 4)\nclass Solution:\n    def reshape(self, to_reshape: TensorType[float]) -> TensorType[float]:\n    \n        return torch.reshape(to_reshape, (to_reshape.size(dim=1)*to_reshape.size(dim=0)//2, 2))\n\n\n    def average(self, to_avg: TensorType[float]) -> TensorType[float]:\n        \n        return torch.mean(to_avg, axis=0)\n\n    def concatenate(self, cat_one: TensorType[float], cat_two: TensorType[float]) -> TensorType[float]:\n\n        return torch.cat((cat_one, cat_two), dim=1)\n\n    def get_loss(self, prediction: TensorType[float], target: TensorType[float]) -> TensorType[float]:\n\n        return torch.nn.functional.mse_loss(input=prediction, target=target)\n```\n\n\n# Dropout\n\nDropout makes neural networks dumber on purpose. We do this to prevent overrfitting and to make a model generalize better.\n\n> **Overfitting**: When training accuracy is greater than testing accuracy.\n\n\nSaid another way,: The model looks incredible when it is training and looking at training data, but the second you give it testing (i.e. real-world or non-training) data, it performs horribly. The model is essentially memorizing the training dataset and not really learning anything. Visually (and from a mathematical perspective), overfitting looks like this: \n\n![Overfitting of data. [Source](https://www.buildalpha.com/how-to-use-out-of-sample-data/)](images/fitting.png){width=60%}\n\nOverfitting is usually caused by the model being too complex. Here, *complex* can mean a few things:\n\n* The model has too many layers\n* Each layer has too many nodes\n\nEssentially, the model is just an equation, and right now that equation is way too complex. This is like having data that can be fit with just a linear equation, but a 10th order Taylor series is being used to approximate it.\n\nDropout aims to solve these problems. Let's say we have a network like this:\n\n\n![Dropout neural network architecture](images/dropout.svg){width=60%}\n\nLet's say that we apply dropout to the entire output layer, but dropout only ends up applying to the first output node, $O_1$. This means that this node is essentially turned off and its connections to the previous layer are severed (see the dotted lines). Mathematically, this equates to setting the equation for $O_1$ equal to zero:\n\n$$\nO_1 = w_1 x + w_2 y + w_3 z + b = 0\n$$\n\nIn PyTorch, this would look like `nn.Dropout(p=0.2)`, where `p` is the propbability that the node is turned off. If we apply dropout to the entire output layer, each node would be turned off (set output or activation equal to zero) independently with probability $p$.\n\nRemember, overfitting occurs ebcause our model is too *complex*. So if dropout is to work, it has to *reduce* our model's complexity. And we can see that is exactly what is happening. In other words, what dropout is doing is making the model more stupid so it doesn't focus on unnecessary/irrelevant noise.\n\nDropout has been found to increase teseting accuracy, especially as models get deeper (i.e. have more layers).\n\n",
    "supporting": [
      "index_files/figure-html"
    ],
    "filters": [],
    "includes": {}
  }
}